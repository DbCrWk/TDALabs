{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Video Sliding Windows</h1>\n",
    "\n",
    "<p>\n",
    "So far we restricted ourselves to 1D time series, but the idea of recovering periodic dynamics with geometry can just as easily apply to multivariate signals.  In this module, we will examine sliding windows of videos as an exmaple.  Many natural videos also have periodicity, such as this video of a woman doing jumping jacks\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "video = io.open('jumpingjacks.ogg', 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Video can be decomposed into a 3D array, which has dimensions width x height x time.  To tease out periodicity in geometric form, we will do the exact same thing as with sliding window 1D signal embeddings, but instead of just one sample per time shift, we need to take every pixel in every frame in the time window.  The figure below depicts this\n",
    "</p>\n",
    "\n",
    "<img src = \"VideoStackTime.svg\"><BR><BR>\n",
    "\n",
    "To see this visually in the video next to PCA of the embedding, look at the following video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video = io.open('jumpingjackssliding.ogg', 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>PCA Preprocessing for Efficiency</h2><BR>\n",
    "One issue we have swept under the rug so far is memory consumption and computational efficiency.  Doing a raw sliding window of every pixel of every frame in the video would blow up in memory.  However, even though there are <code>WH</code> pixels in each frame, there are only <code>N</code> frames in the video.  This means that each frame in the video can be represented in an <code>(N-1)</code> dimensional subspace of the pixel space, and the coordinates of this subspace can be used in lieu of the pixels in the sliding window embedding.  This can be done efficiently with a PCA step before the sliding window embedding.  Run the cell below to load code that does PCA efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Do all of the imports and setup inline plotting\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.interpolate\n",
    "\n",
    "from TDA import *\n",
    "from VideoTools import *\n",
    "\n",
    "##Here is the actual PCA code\n",
    "def getPCAVideo(I):\n",
    "    ICov = I.dot(I.T)\n",
    "    [lam, V] = linalg.eigh(ICov)\n",
    "    V = V*np.sqrt(lam[None, :])\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Jumping Jacks Example Live Demo</h2><BR>\n",
    "Let's now load in code that does sliding window embeddings of videos.  The code is very similar to the 1D case, and it has the exact same parameters.  The only difference is that each sliding window lives in a Euclidean space of dimension the number of pixels times <code>dim</code>.  We're also using linear interpolation instead of spline interpolation to keep things fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSlidingWindowVideo(I, dim, Tau, dT):\n",
    "    N = I.shape[0] #Number of frames\n",
    "    P = I.shape[1] #Number of pixels (possibly after PCA)\n",
    "    pix = np.arange(P)\n",
    "    NWindows = int(np.floor((N-dim*Tau)/dT))\n",
    "    X = np.zeros((NWindows, dim*P))\n",
    "    idx = np.arange(N)\n",
    "    for i in range(NWindows):\n",
    "        idxx = dT*i + Tau*np.arange(dim)\n",
    "        start = int(np.floor(idxx[0]))\n",
    "        end = int(np.ceil(idxx[-1]))+2\n",
    "        if end >= I.shape[0]:\n",
    "            X = X[0:i, :]\n",
    "            break\n",
    "        f = scipy.interpolate.interp2d(pix, idx[start:end+1], I[idx[start:end+1], :], kind='linear')\n",
    "        X[i, :] = f(pix, idxx).flatten()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Finally, let's load in the jumping jacks video, perform PCA, do a sliding window, and examine the sliding window embedding using TDA.  As before, you should tweak the parameters of the sliding window embedding and study the effect on the geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load in video and do PCA to compress dimension\n",
    "(X, FrameDims) = loadVideo(\"jumpingjacks.ogg\")\n",
    "X = getPCAVideo(X)\n",
    "\n",
    "#Given that the period is 30 frames per cycle, choose a dimension and a Tau that capture \n",
    "#this motion in the roundest possible way\n",
    "#Plot persistence diagram and PCA\n",
    "dim = 30\n",
    "Tau = 1\n",
    "dT = 1\n",
    "\n",
    "#Get sliding window video\n",
    "XS = getSlidingWindowVideo(X, dim, Tau, dT)\n",
    "\n",
    "#Mean-center and normalize sliding window\n",
    "XS = XS - np.mean(XS, 1)[:, None]\n",
    "XS = XS/np.sqrt(np.sum(XS**2, 1))[:, None]\n",
    "\n",
    "#Get persistence diagrams\n",
    "PDs = doRipsFiltration(XS, 1)\n",
    "\n",
    "#Do PCA for visualization\n",
    "pca = PCA(n_components = 3)\n",
    "Y = pca.fit_transform(XS)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax1 = fig.add_subplot(121)\n",
    "plotDGMAx(ax1, PDs[1])\n",
    "ax1.set_title(\"1D Persistence Diagram\")\n",
    "\n",
    "c = plt.get_cmap('jet')\n",
    "C = c(np.array(np.round(np.linspace(0, 255, Y.shape[0])), dtype=np.int32))\n",
    "C = C[:, 0:3]\n",
    "ax2 = fig.add_subplot(122, projection = '3d')\n",
    "ax2.set_title(\"PCA of Sliding Window Embedding\")\n",
    "ax2.scatter(Y[:, 0], Y[:, 1], Y[:, 2], c=C)\n",
    "ax2.set_aspect('equal', 'datalim')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Periodicities in The KTH Dataset</h1><BR>\n",
    "\n",
    "We will now examine videos from the <a href = \"http://www.nada.kth.se/cvap/actions/\">KTH dataset</a>, which is a repository of black and white videos of human activities.  It consists of 25 subjects performing 6 different actions in each of 4 scenarios.  We will use the algorithms developed in this section to measure and rank the periodicity of the different video clips.\n",
    "\n",
    "<h2>Varying Window Length</h2><BR>\n",
    "For our first experiment, we will be showing some precomputed results of varying the sliding window length, while choosing Tau and dT appropriately to keep the dimension and the number of points, respectively, the same in the sliding window embedding.  As an example, we will apply it to one of the videos of a subject waving his hands back and forth, as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video = io.open('KTH/handwaving/person01_handwaving_d1_uncomp.ogg', 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have done some additional preprocessing, including applying a bandpass filter to each PCA pixel to cut down on drift in the video.  Below we show a video varying the window size of the embedding and plotting the persistence diagram, \"self-similarity matrix\" (distance matrix), and PCA of the embedding, as well as an evolving plot of the maximum persistence versus window size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video = io.open('Handwaving_Deriv10_Block160_PCA10.ogg', 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the maximum persistence peaks at around 40 frames, which is the period of each hand wave.  This is what the theory we developed for 1D time series would have predicted as the roundest window.<BR>\n",
    "\n",
    "<h2>KTH Dataset Rankings</h2><BR>\n",
    "For the final experiment, students will split up into groups and run code on different subsets of the KTH dataset which ranks the video clips in decreasing order of periodicity.  As an example, <a href = \"VideoResults/index.html\">click here</a> to see the rankings of all activities for the first 4 subjects.  Groups will run the code in <a href = \"KTHTests.py\">KTHTests.py</a> after modifying it to go through the appropriate subset of the database by changing lines 53 through 55.  A new web page will be generated <a href = \"VideoResults/index.html\">here</a> to show the resulting rankings.  Note that a fixed window length of 20 frames is maintained throughout all of the experiments.  Feel free to tweak the window size (\"win\" on line 72), the dimension of the embedding (\"dim\" on line 73), or any other parameters you think would make the results more meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>Summary</h1>\n",
    "<ul>\n",
    "<li>Periodicity can be studied on general time series data, including multivariate time series such as video</li>\n",
    "<li>Computational tricks, such as PCA, can be employed to make sliding window videos computationally tractable</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
